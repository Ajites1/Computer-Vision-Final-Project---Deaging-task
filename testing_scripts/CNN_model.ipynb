{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c327edf-161e-4c6b-bcb6-69ea69c51fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159cf383-4f18-4bde-a361-724309e9326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path, transform=None):\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images = []\n",
    "        self.ages = []\n",
    "        \n",
    "        print(f\"Loading dataset from: {data_path}\")\n",
    "\n",
    "        \n",
    "\n",
    "        # Load from JSON file\n",
    "        with open(data_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Check if nested structure (has \"root\" key)\n",
    "        if \"root\" in data:\n",
    "            data = data[\"root\"]\n",
    "        \n",
    "        # Flatten the nested dictionary into lists\n",
    "        for age_str, content in data.items():\n",
    "            age_group = int(age_str)  # Age group is already the key\n",
    "\n",
    "            for img_id, img_path in content.items():\n",
    "                self.images.append(img_path)\n",
    "                self.ages.append(age_group)\n",
    "\n",
    "        \n",
    "        print(f\"Loaded {len(self.images)} image paths from JSON\")\n",
    "            \n",
    "       \n",
    "        # Print age distribution\n",
    "        # age_counts = [0] * (26)\n",
    "        # #print(self.ages)\n",
    "        # for age in self.ages:\n",
    "        #     # print(age)\n",
    "        #     # print(age//10)\n",
    "        #     age_counts[age] += 1\n",
    "        \n",
    "        # print(\"\\nAge distribution:\")\n",
    "        # for i, count in enumerate(age_counts):\n",
    "        #     print(f\"  {i*4}-{i*4+4} years: {count} images\")\n",
    "        print(max(self.ages))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Load from path stored in JSON\n",
    "        image_path = self.images[idx]\n",
    "        image = np.load(image_path)\n",
    "        \n",
    "        \n",
    "        age = self.ages[idx]\n",
    "        \n",
    "        # Convert numpy array to PIL Image\n",
    "        # Handle different array formats\n",
    "        if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "            # If normalized to [0, 1], scale to [0, 255]\n",
    "            if image.max() <= 1.0:\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image = image.astype(np.uint8)\n",
    "        elif image.dtype != np.uint8:\n",
    "            image = image.astype(np.uint8)\n",
    "        \n",
    "        # Handle channel order: (H, W, C) or (C, H, W)\n",
    "        if image.ndim == 3:\n",
    "            if image.shape[0] == 3 or image.shape[0] == 1:\n",
    "                # (C, H, W) -> (H, W, C)\n",
    "                image = np.transpose(image, (1, 2, 0))\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        if image.shape[-1] == 1:\n",
    "            image = Image.fromarray(image.squeeze(), mode='L').convert('RGB')\n",
    "        else:\n",
    "            image = Image.fromarray(image, mode='RGB')\n",
    "        resized_pil_image = image.resize((128, 128), Image.LANCZOS)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, age\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc066d5f-dda5-4fc2-bbd8-c7a5c03ef9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes: input face image + target age\n",
    "    Returns: face aged to target age\n",
    "    \"\"\"\n",
    "    def __init__(self, num_age_classes=111):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # ENCODER: Compress image to features\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 128x128 -> 64x64\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 64x64 -> 32x32\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 32x32 -> 16x16\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 16x16 -> 8x8\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # AGE CONDITIONING: Add age information\n",
    "        self.age_embedding = nn.Embedding(num_age_classes, 512 * 8 * 8)\n",
    "        \n",
    "        # DECODER: Reconstruct image with new age\n",
    "        self.decoder = nn.Sequential(\n",
    "            # 8x8 -> 16x16\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 16x16 -> 32x32\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 32x32 -> 64x64\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 64x64 -> 128x128\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()  # Output in range [-1, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, target_age):\n",
    "        # Encode the face\n",
    "        features = self.encoder(img)\n",
    "        \n",
    "        # Add age information\n",
    "        batch_size = img.size(0)\n",
    "        age_vec = self.age_embedding(target_age)\n",
    "        age_vec = age_vec.view(batch_size, 512, 8, 8)\n",
    "        #print(features.shape)\n",
    "        #print(age_vec.shape)\n",
    "        combined = features + age_vec\n",
    "        \n",
    "        # Decode with new age\n",
    "        output = self.decoder(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da36273-a734-49fe-ae75-18431dc6af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes: an image\n",
    "    Returns: \n",
    "        - Is it real or fake? (validity)\n",
    "        - What age is this person? (age classification)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_age_classes=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            # 128x128 -> 64x64\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 64x64 -> 32x32\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 32x32 -> 16x16\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 16x16 -> 8x8\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Real/Fake head\n",
    "        self.validity = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=8, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Age classification head\n",
    "        self.age_classifier = nn.Sequential(\n",
    "            nn.Conv2d(512, num_age_classes, kernel_size=8, stride=1, padding=0),\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        features = self.features(img)\n",
    "        #print(features.shape)\n",
    "        validity = self.validity(features).view(-1, 1)\n",
    "        age_logits = self.age_classifier(features).view(-1, 111)\n",
    "        return validity, age_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38eb12b9-a7a0-4a8d-9dd5-4a2b7745b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: /projects/standard/csci5561/shared/G8/data/qtk.json\n",
      "Loaded 66982 image paths from JSON\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "dataset = AgeDataset(\"/projects/standard/csci5561/shared/G8/data/qtk.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a88eca0-f0d5-4e99-abbc-2deb9e212097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: /projects/standard/csci5561/shared/G8/data/face_age.json\n",
      "Loaded 19556 image paths from JSON\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "dataset = AgeDataset(\"/projects/standard/csci5561/shared/G8/data/face_age.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c658d06-a503-433f-8b80-584ef735679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_age_progression_gan(\n",
    "    data_path,\n",
    "    num_epochs=100,\n",
    "    batch_size=4,\n",
    "    lr_g=0.0002,\n",
    "    lr_d=0.0002,\n",
    "    image_size=128,\n",
    "    save_interval=10,\n",
    "    sample_interval=5,\n",
    "    output_dir=\"training_output_CNN\",\n",
    "    device='cuda'\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete training pipeline\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to JSON file (mode='json'), folder (mode='individual'), \n",
    "                   or data files (mode='single'/'dict')\n",
    "\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    os.makedirs(f\"{output_dir}/checkpoints\", exist_ok=True)\n",
    "    os.makedirs(f\"{output_dir}/samples\", exist_ok=True)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING AGE PROGRESSION GAN\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Data path: {data_path}\")\n",
    "    print(f\"Epochs: {num_epochs}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Image size: {image_size}x{image_size}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Data preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = AgeDataset(data_path, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTotal batches per epoch: {len(dataloader)}\\n\")\n",
    "    \n",
    "    # Initialize models\n",
    "    generator = Generator(num_age_classes=111).to(device)\n",
    "    discriminator = Discriminator(num_age_classes=111).to(device)\n",
    "    \n",
    "    print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "    print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\\n\")\n",
    "    \n",
    "    # Loss functions\n",
    "    adversarial_loss = nn.BCELoss()\n",
    "    age_loss = nn.CrossEntropyLoss()\n",
    "    reconstruction_loss = nn.L1Loss()\n",
    "    \n",
    "    # Optimizers\n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "        \n",
    "        epoch_d_loss = 0\n",
    "        epoch_g_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for i, (real_imgs, real_ages) in enumerate(progress_bar):\n",
    "            batch_size_actual = real_imgs.size(0)\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            real_ages = real_ages.to(device)\n",
    "            \n",
    "            # Sample random target ages for aging\n",
    "            target_ages = torch.randint(0, 111, (batch_size_actual,), device=device)\n",
    "            \n",
    "            # Labels\n",
    "            real_labels = torch.ones(batch_size_actual, 1, device=device)\n",
    "            fake_labels = torch.zeros(batch_size_actual, 1, device=device)\n",
    "            \n",
    "            # =============================\n",
    "            # TRAIN DISCRIMINATOR\n",
    "            # =============================\n",
    "            optimizer_d.zero_grad()\n",
    "            \n",
    "            # Real images\n",
    "            \n",
    "            real_validity, real_age_pred = discriminator(real_imgs)\n",
    "            d_real_adv_loss = adversarial_loss(real_validity, real_labels)\n",
    "            #print(real_age_pred.shape)\n",
    "            d_real_age_loss = age_loss(real_age_pred, real_ages)\n",
    "            \n",
    "            # Fake images\n",
    "            \n",
    "            fake_imgs = generator(real_imgs, target_ages)\n",
    "            fake_validity, fake_age_pred = discriminator(fake_imgs.detach())\n",
    "            d_fake_adv_loss = adversarial_loss(fake_validity, fake_labels)\n",
    "            #print(\"got to here\")\n",
    "            d_fake_age_loss = age_loss(fake_age_pred, target_ages)\n",
    "            #print(\"maybe error here\")\n",
    "            # Total discriminator loss\n",
    "            d_loss = (d_real_adv_loss + d_fake_adv_loss) + 0.5 * (d_real_age_loss + d_fake_age_loss)\n",
    "            d_loss.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            # =============================\n",
    "            # TRAIN GENERATOR\n",
    "            # =============================\n",
    "            optimizer_g.zero_grad()\n",
    "            \n",
    "            # Generate fake images\n",
    "            fake_imgs = generator(real_imgs, target_ages)\n",
    "            fake_validity, fake_age_pred = discriminator(fake_imgs)\n",
    "            \n",
    "            # Adversarial loss: fool discriminator\n",
    "            \n",
    "            g_adv_loss = adversarial_loss(fake_validity, real_labels)\n",
    "            \n",
    "            # Age loss: correct age\n",
    "            \n",
    "            g_age_loss = age_loss(fake_age_pred, target_ages)\n",
    "            \n",
    "            # Identity preservation: when age doesn't change, preserve identity\n",
    "            same_age_mask = (target_ages == real_ages)\n",
    "            if same_age_mask.any():\n",
    "                g_recon_loss = reconstruction_loss(\n",
    "                    fake_imgs[same_age_mask],\n",
    "                    real_imgs[same_age_mask]\n",
    "                )\n",
    "            else:\n",
    "                g_recon_loss = torch.tensor(0.0, device=device)\n",
    "            \n",
    "            # Total generator loss\n",
    "            g_loss = g_adv_loss + g_age_loss + 10.0 * g_recon_loss\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "            \n",
    "            # Update progress bar\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            progress_bar.set_postfix({\n",
    "                'D_loss': f'{d_loss.item():.4f}',\n",
    "                'G_loss': f'{g_loss.item():.4f}'\n",
    "            })\n",
    "        \n",
    "        # Print epoch summary\n",
    "        avg_d_loss = epoch_d_loss / len(dataloader)\n",
    "        avg_g_loss = epoch_g_loss / len(dataloader)\n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"  Average D Loss: {avg_d_loss:.4f}\")\n",
    "        print(f\"  Average G Loss: {avg_g_loss:.4f}\\n\")\n",
    "        \n",
    "        # Save sample images\n",
    "        if (epoch + 1) % sample_interval == 0:\n",
    "            save_samples(generator, real_imgs[:8], epoch+1, output_dir, device)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'generator': generator.state_dict(),\n",
    "                'discriminator': discriminator.state_dict(),\n",
    "                'optimizer_g': optimizer_g.state_dict(),\n",
    "                'optimizer_d': optimizer_d.state_dict(),\n",
    "            }\n",
    "            checkpoint_path = f\"{output_dir}/checkpoints/checkpoint_epoch_{epoch+1}.pth\"\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            print(f\"✓ Saved checkpoint: {checkpoint_path}\\n\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6d50c2-51b7-42fe-b53f-36f4b0ddad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(generator, real_imgs, epoch, output_dir, device):\n",
    "    \"\"\"Generate and save sample aged faces\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        # Show aging progression: 20s, 40s, 60s, 80s\n",
    "        age_groups = [20, 40, 60, 80]  # 20s, 40s, 60s, 80s\n",
    "        \n",
    "        samples = [real_imgs]\n",
    "        for age in age_groups:\n",
    "            target_ages = torch.full((real_imgs.size(0),), age, device=device)\n",
    "            aged_imgs = generator(real_imgs, target_ages)\n",
    "            samples.append(aged_imgs)\n",
    "        \n",
    "        # Concatenate all samples\n",
    "        samples = torch.cat(samples, dim=0)\n",
    "        \n",
    "        # Save grid\n",
    "        save_image(\n",
    "            samples,\n",
    "            f\"{output_dir}/samples/epoch_{epoch}.png\",\n",
    "            nrow=real_imgs.size(0),\n",
    "            normalize=True,\n",
    "            value_range=(-1, 1)\n",
    "        )\n",
    "    generator.train()\n",
    "    print(f\"✓ Saved samples: {output_dir}/samples/epoch_{epoch}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec48f23-f60d-4adb-91c7-0dc30e73fea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING AGE PROGRESSION GAN\n",
      "============================================================\n",
      "Device: cuda:1\n",
      "Data path: /projects/standard/csci5561/shared/G8/data/face_age.json\n",
      "Epochs: 100\n",
      "Batch size: 4\n",
      "Image size: 128x128\n",
      "============================================================\n",
      "\n",
      "Loading dataset from: /projects/standard/csci5561/shared/G8/data/face_age.json\n",
      "Loaded 19556 image paths from JSON\n",
      "110\n",
      "\n",
      "Total batches per epoch: 4889\n",
      "\n",
      "Generator parameters: 9,152,515\n",
      "Discriminator parameters: 6,428,464\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|                                                                                                                              | 0/4889 [00:00<?, ?it/s]/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "Epoch 1/100: 100%|█████████████████████████████████████████████████████████████████████████████████████| 4889/4889 [01:00<00:00, 81.12it/s, D_loss=2.2087, G_loss=3.7569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "  Average D Loss: 3.2899\n",
      "  Average G Loss: 4.5316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:   0%|                                                                                                                              | 0/4889 [00:00<?, ?it/s]/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "Epoch 2/100: 100%|█████████████████████████████████████████████████████████████████████████████████████| 4889/4889 [00:59<00:00, 81.97it/s, D_loss=0.2034, G_loss=8.2064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "  Average D Loss: 1.3804\n",
      "  Average G Loss: 5.2435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100:   0%|                                                                                                                              | 0/4889 [00:00<?, ?it/s]/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "Epoch 3/100: 100%|█████████████████████████████████████████████████████████████████████████████████████| 4889/4889 [01:00<00:00, 80.80it/s, D_loss=1.8574, G_loss=4.2490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "  Average D Loss: 0.8945\n",
      "  Average G Loss: 5.8511\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100:   0%|                                                                                                                              | 0/4889 [00:00<?, ?it/s]/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "Epoch 4/100: 100%|█████████████████████████████████████████████████████████████████████████████████████| 4889/4889 [01:00<00:00, 80.99it/s, D_loss=1.0354, G_loss=8.5311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary:\n",
      "  Average D Loss: 0.8382\n",
      "  Average G Loss: 5.4840\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100:   0%|                                                                                                                              | 0/4889 [00:00<?, ?it/s]/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "Epoch 5/100: 100%|█████████████████████████████████████████████████████████████████████████████████████| 4889/4889 [01:00<00:00, 80.60it/s, D_loss=0.2009, G_loss=4.6354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Summary:\n",
      "  Average D Loss: 0.8079\n",
      "  Average G Loss: 5.1712\n",
      "\n",
      "✓ Saved samples: training_output_CNN/samples/epoch_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100:   0%|                                                                                                                              | 0/4889 [00:00<?, ?it/s]/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "Epoch 6/100: 100%|█████████████████████████████████████████████████████████████████████████████████████| 4889/4889 [00:59<00:00, 82.33it/s, D_loss=0.1298, G_loss=3.5367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Summary:\n",
      "  Average D Loss: 0.8453\n",
      "  Average G Loss: 4.6377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100:   0%|                                                                                                                              | 0/4889 [00:00<?, ?it/s]/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "/tmp/ipykernel_1787959/4016586263.py:80: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  image = Image.fromarray(image, mode='RGB')\n",
      "Epoch 7/100:  26%|█████████████████████▊                                                               | 1252/4889 [00:15<00:43, 83.28it/s, D_loss=2.0145, G_loss=5.9109]"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/projects/standard/csci5561/shared/G8/data/face_age.json\"\n",
    "\n",
    "NUM_EPOCHS = 100                    # Number of training epochs\n",
    "BATCH_SIZE = 4                     # Batch size (reduce if out of memory)\n",
    "IMAGE_SIZE = 128                    # Image resolution\n",
    "LEARNING_RATE_G = 0.0002           # Generator learning rate\n",
    "LEARNING_RATE_D = 0.0002           # Discriminator learning rate\n",
    "DEVICE = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "#DEVICE = \"cpu\"\n",
    "# =============================\n",
    "# START TRAINING!\n",
    "# =============================\n",
    "\n",
    "generator, discriminator = train_age_progression_gan(\n",
    "    data_path=DATA_PATH,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr_g=LEARNING_RATE_G,\n",
    "    lr_d=LEARNING_RATE_D,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    save_interval=10,      # Save checkpoint every 10 epochs\n",
    "    sample_interval=5,     # Generate samples every 5 epochs\n",
    "    output_dir=\"training_output_CNN\",\n",
    "    device=DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cc1c6-c0e9-41ad-9f7d-7a05bdef6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = np.load(\"/projects/standard/csci5561/shared/G8/data/face_age_Numpy/9773_100.npy\")\n",
    "if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "    # If normalized to [0, 1], scale to [0, 255]\n",
    "    if image.max() <= 1.0:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    else:\n",
    "        image = image.astype(np.uint8)\n",
    "elif image.dtype != np.uint8:\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "# Handle channel order: (H, W, C) or (C, H, W)\n",
    "if image.ndim == 3:\n",
    "    if image.shape[0] == 3 or image.shape[0] == 1:\n",
    "        # (C, H, W) -> (H, W, C)\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "print(image.shape)\n",
    "pil_image = Image.fromarray(image)\n",
    "resized_pil_image = pil_image.resize((128, 128), Image.LANCZOS) # LANCZOS is a high-quality filter\n",
    "\n",
    "# Convert the resized PIL Image back to a NumPy array\n",
    "x = np.array(resized_pil_image)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54cb57-214d-44dd-9a3a-20ec390747b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
